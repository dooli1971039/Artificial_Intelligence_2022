{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[2022-1 AI] Live Session 4-1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 2022-1 Artificial Intelligence (01)\n",
        "## Live Session #4-1: Machine Translation (seq2seq) with RNN\n",
        "---\n",
        "Copyright (c) Prof. Jaehyeong Sim \n",
        "\n",
        "Department of Computer Science and Engineering\n",
        "\n",
        "Ewha Womans University\n",
        "\n",
        "ref: https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html"
      ],
      "metadata": {
        "id": "JJeY52mkwqe5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "i1fEkr-P4z9Y"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import unicodedata\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 33000"
      ],
      "metadata": {
        "id": "7gN-x8Cq5gAr"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_ascii(s):\n",
        "  # Remove French accent\n",
        "  # e.g. 'déjà diné' -> deja dine\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "                   if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(sent):\n",
        "  sent = to_ascii(sent.lower())\n",
        "\n",
        "  # Insert whitespace between words and puncutation\n",
        "  # e.g. \"I am a student.\" => \"I am a student .\"\n",
        "  sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
        "\n",
        "  # Replace with whitespace except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
        "\n",
        "  # Replace multiple whitespaces with single one\n",
        "  sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "  return sent"
      ],
      "metadata": {
        "id": "1yAKoTZb544t"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing test\n",
        "en_sent = u\"Have you had dinner?\"\n",
        "fr_sent = u\"Avez-vous déjà diné?\"\n",
        "\n",
        "print('English sentence before preprocessing :', en_sent)\n",
        "print('English sentence after preprocessing :',preprocess_sentence(en_sent))\n",
        "print('French sentence before preprocessing :', fr_sent)\n",
        "print('French sentence after preprocessing :', preprocess_sentence(fr_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQaYY1UE6eRd",
        "outputId": "ceaa582e-0ad0-4f52-83fe-2058318f5dd6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English sentence before preprocessing : Have you had dinner?\n",
            "English sentence after preprocessing : have you had dinner ?\n",
            "French sentence before preprocessing : Avez-vous déjà diné?\n",
            "French sentence after preprocessing : avez vous deja dine ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_preprocessed_data():\n",
        "  encoder_input, decoder_input, decoder_target = [], [], []\n",
        "\n",
        "  with open(\"fra.txt\", \"r\") as lines:\n",
        "    for i, line in enumerate(lines):\n",
        "      # Split source and target data\n",
        "      src_line, tar_line, _ = line.strip().split('\\t')\n",
        "\n",
        "      # Preprocess source \n",
        "      src_line = [w for w in preprocess_sentence(src_line).split()]\n",
        "\n",
        "      # Preprocess target\n",
        "      tar_line = preprocess_sentence(tar_line)\n",
        "      tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
        "      tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
        "\n",
        "      encoder_input.append(src_line)\n",
        "      decoder_input.append(tar_line_in)\n",
        "      decoder_target.append(tar_line_out)\n",
        "\n",
        "      if i == num_samples - 1:\n",
        "        break\n",
        "\n",
        "  return encoder_input, decoder_input, decoder_target"
      ],
      "metadata": {
        "id": "5-j0Ba386iXo"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
        "print('Encoder input :',sents_en_in[:5])\n",
        "print('Decoder input :',sents_fra_in[:5])\n",
        "print('Decoder label:',sents_fra_out[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-AJ1ppx6kZY",
        "outputId": "63de5f51-053b-44f2-9f11-f50a5680eb7f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder input : [['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.'], ['hi', '.']]\n",
            "Decoder input : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!'], ['<sos>', 'salut', '.']]\n",
            "Decoder label: [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>'], ['salut', '.', '<eos>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_en.fit_on_texts(sents_en_in)\n",
        "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
        "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
        "\n",
        "tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
        "\n",
        "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
        "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
        "\n",
        "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)\n",
        "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
      ],
      "metadata": {
        "id": "UYPlT24R6oYO"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of encoder input :',encoder_input.shape)\n",
        "print('Shape of decoder input :',decoder_input.shape)\n",
        "print('Shape of decoder label :',decoder_target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls4izDJ86q5H",
        "outputId": "4fed32f3-7c5d-44d5-dfe2-4bc5aff8d73f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of encoder input : (33000, 8)\n",
            "Shape of decoder input : (33000, 16)\n",
            "Shape of decoder label : (33000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
        "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
        "print(\"English vocabulary size : {:d}, French vocabulary size : {:d}\".format(src_vocab_size, tar_vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7P7IweB6wHR",
        "outputId": "6d304ff3-e91d-48cb-8f40-93deae4e6adc"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English vocabulary size : 4672, French vocabulary size : 8153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_to_index = tokenizer_en.word_index\n",
        "index_to_src = tokenizer_en.index_word\n",
        "tar_to_index = tokenizer_fra.word_index\n",
        "index_to_tar = tokenizer_fra.index_word"
      ],
      "metadata": {
        "id": "wa2kdFKf6yL3"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print('Random sequence :',indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJOeIf6Z60iv",
        "outputId": "d9aadd42-a6be-40d5-8413-262158669ac9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random sequence : [28638 19499  4419 ... 15933  9795 20858]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]"
      ],
      "metadata": {
        "id": "_24g39eI683E"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_of_val = int(33000*0.1)\n",
        "print('Validation data size :',n_of_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h97OLhrq7BuV",
        "outputId": "3091717c-aaa0-4c61-e70d-a356593be2be"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation data size : 3300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]"
      ],
      "metadata": {
        "id": "ZKgYzm_k7DrN"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "HIxsNQzX7FB5"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 64\n",
        "hidden_units = 64"
      ],
      "metadata": {
        "id": "XZs9JRG67HGC"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb = Embedding(src_vocab_size, embedding_dim)(encoder_inputs)\n",
        "enc_masking = Masking(mask_value=0.0)(enc_emb)\n",
        "encoder_lstm = LSTM(hidden_units, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
        "encoder_states = [state_h, state_c]"
      ],
      "metadata": {
        "id": "LKfBr7fW7IlA"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(tar_vocab_size, hidden_units) \n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
        "\n",
        "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True) \n",
        "\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
        "                                     initial_state=encoder_states)\n",
        "\n",
        "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "sHhtntLU7MTz"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model inputs and outputs\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "lMmFN_bC7PZA"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
        "          batch_size=128, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjzEZzE_7RGO",
        "outputId": "99c26fba-f017-4d95-ec81-42643b93114f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "233/233 [==============================] - 17s 42ms/step - loss: 3.4273 - acc: 0.6089 - val_loss: 2.0306 - val_acc: 0.6197\n",
            "Epoch 2/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 1.8669 - acc: 0.6820 - val_loss: 1.7406 - val_acc: 0.7397\n",
            "Epoch 3/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 1.6480 - acc: 0.7483 - val_loss: 1.5688 - val_acc: 0.7582\n",
            "Epoch 4/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 1.5044 - acc: 0.7609 - val_loss: 1.4687 - val_acc: 0.7695\n",
            "Epoch 5/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 1.4119 - acc: 0.7727 - val_loss: 1.3925 - val_acc: 0.7795\n",
            "Epoch 6/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 1.3376 - acc: 0.7829 - val_loss: 1.3327 - val_acc: 0.7876\n",
            "Epoch 7/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 1.2743 - acc: 0.7922 - val_loss: 1.2833 - val_acc: 0.7962\n",
            "Epoch 8/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 1.2189 - acc: 0.8008 - val_loss: 1.2388 - val_acc: 0.8066\n",
            "Epoch 9/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 1.1642 - acc: 0.8107 - val_loss: 1.1944 - val_acc: 0.8122\n",
            "Epoch 10/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 1.1119 - acc: 0.8174 - val_loss: 1.1508 - val_acc: 0.8173\n",
            "Epoch 11/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 1.0653 - acc: 0.8230 - val_loss: 1.1157 - val_acc: 0.8217\n",
            "Epoch 12/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 1.0231 - acc: 0.8278 - val_loss: 1.0854 - val_acc: 0.8261\n",
            "Epoch 13/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.9843 - acc: 0.8320 - val_loss: 1.0594 - val_acc: 0.8285\n",
            "Epoch 14/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.9491 - acc: 0.8360 - val_loss: 1.0375 - val_acc: 0.8321\n",
            "Epoch 15/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.9167 - acc: 0.8401 - val_loss: 1.0198 - val_acc: 0.8327\n",
            "Epoch 16/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.8866 - acc: 0.8431 - val_loss: 0.9944 - val_acc: 0.8361\n",
            "Epoch 17/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.8582 - acc: 0.8461 - val_loss: 0.9767 - val_acc: 0.8386\n",
            "Epoch 18/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.8314 - acc: 0.8486 - val_loss: 0.9648 - val_acc: 0.8395\n",
            "Epoch 19/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.8058 - acc: 0.8511 - val_loss: 0.9446 - val_acc: 0.8418\n",
            "Epoch 20/50\n",
            "233/233 [==============================] - 7s 28ms/step - loss: 0.7805 - acc: 0.8537 - val_loss: 0.9312 - val_acc: 0.8430\n",
            "Epoch 21/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.7571 - acc: 0.8559 - val_loss: 0.9187 - val_acc: 0.8440\n",
            "Epoch 22/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.7342 - acc: 0.8584 - val_loss: 0.9056 - val_acc: 0.8455\n",
            "Epoch 23/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.7121 - acc: 0.8608 - val_loss: 0.8957 - val_acc: 0.8470\n",
            "Epoch 24/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.6923 - acc: 0.8628 - val_loss: 0.8827 - val_acc: 0.8476\n",
            "Epoch 25/50\n",
            "233/233 [==============================] - 7s 28ms/step - loss: 0.6717 - acc: 0.8652 - val_loss: 0.8728 - val_acc: 0.8483\n",
            "Epoch 26/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.6516 - acc: 0.8675 - val_loss: 0.8672 - val_acc: 0.8493\n",
            "Epoch 27/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.6344 - acc: 0.8695 - val_loss: 0.8550 - val_acc: 0.8511\n",
            "Epoch 28/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.6147 - acc: 0.8722 - val_loss: 0.8458 - val_acc: 0.8520\n",
            "Epoch 29/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.5976 - acc: 0.8741 - val_loss: 0.8400 - val_acc: 0.8536\n",
            "Epoch 30/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.5803 - acc: 0.8769 - val_loss: 0.8325 - val_acc: 0.8542\n",
            "Epoch 31/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.5638 - acc: 0.8790 - val_loss: 0.8267 - val_acc: 0.8551\n",
            "Epoch 32/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.5493 - acc: 0.8805 - val_loss: 0.8189 - val_acc: 0.8560\n",
            "Epoch 33/50\n",
            "233/233 [==============================] - 7s 28ms/step - loss: 0.5336 - acc: 0.8829 - val_loss: 0.8145 - val_acc: 0.8565\n",
            "Epoch 34/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.5185 - acc: 0.8854 - val_loss: 0.8082 - val_acc: 0.8581\n",
            "Epoch 35/50\n",
            "233/233 [==============================] - 7s 28ms/step - loss: 0.5045 - acc: 0.8875 - val_loss: 0.8052 - val_acc: 0.8585\n",
            "Epoch 36/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.4919 - acc: 0.8894 - val_loss: 0.8035 - val_acc: 0.8585\n",
            "Epoch 37/50\n",
            "233/233 [==============================] - 7s 28ms/step - loss: 0.4787 - acc: 0.8918 - val_loss: 0.7979 - val_acc: 0.8603\n",
            "Epoch 38/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.4660 - acc: 0.8935 - val_loss: 0.7929 - val_acc: 0.8612\n",
            "Epoch 39/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.4534 - acc: 0.8960 - val_loss: 0.7916 - val_acc: 0.8607\n",
            "Epoch 40/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.4419 - acc: 0.8980 - val_loss: 0.7885 - val_acc: 0.8614\n",
            "Epoch 41/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.4306 - acc: 0.8999 - val_loss: 0.7854 - val_acc: 0.8630\n",
            "Epoch 42/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.4195 - acc: 0.9024 - val_loss: 0.7847 - val_acc: 0.8625\n",
            "Epoch 43/50\n",
            "233/233 [==============================] - 7s 28ms/step - loss: 0.4099 - acc: 0.9039 - val_loss: 0.7831 - val_acc: 0.8642\n",
            "Epoch 44/50\n",
            "233/233 [==============================] - 7s 28ms/step - loss: 0.4010 - acc: 0.9057 - val_loss: 0.7801 - val_acc: 0.8641\n",
            "Epoch 45/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.3899 - acc: 0.9080 - val_loss: 0.7775 - val_acc: 0.8647\n",
            "Epoch 46/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.3803 - acc: 0.9100 - val_loss: 0.7767 - val_acc: 0.8662\n",
            "Epoch 47/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.3734 - acc: 0.9110 - val_loss: 0.7755 - val_acc: 0.8665\n",
            "Epoch 48/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.3647 - acc: 0.9127 - val_loss: 0.7742 - val_acc: 0.8656\n",
            "Epoch 49/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.3553 - acc: 0.9147 - val_loss: 0.7730 - val_acc: 0.8678\n",
            "Epoch 50/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.3472 - acc: 0.9163 - val_loss: 0.7745 - val_acc: 0.8668\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa84dcad490>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Design decoder for translation\n",
        "decoder_state_input_h = Input(shape=(hidden_units,))\n",
        "decoder_state_input_c = Input(shape=(hidden_units,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# Reusing embedding layer\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "\n",
        "# Next word prediction\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "# Modified decoder\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "metadata": {
        "id": "n3fU5Cts7Zc_"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # Create an integer for <sos>\n",
        "  target_seq = np.zeros((1,1))\n",
        "  target_seq[0, 0] = tar_to_index['<sos>']\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "\n",
        "  while not stop_condition:\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "    decoded_sentence += ' '+sampled_char\n",
        "\n",
        "    if (sampled_char == '<eos>' or\n",
        "        len(decoded_sentence) > 50):\n",
        "        stop_condition = True\n",
        "\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    states_value = [h, c]\n",
        "\n",
        "  return decoded_sentence"
      ],
      "metadata": {
        "id": "AXxT9kvr7dRP"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seq_to_src(input_seq):\n",
        "  sentence = ''\n",
        "  for encoded_word in input_seq:\n",
        "    if(encoded_word != 0):\n",
        "      sentence = sentence + index_to_src[encoded_word] + ' '\n",
        "  return sentence\n",
        "\n",
        "def seq_to_tar(input_seq):\n",
        "  sentence = ''\n",
        "  for encoded_word in input_seq:\n",
        "    if(encoded_word != 0 and encoded_word != tar_to_index['<sos>'] and encoded_word != tar_to_index['<eos>']):\n",
        "      sentence = sentence + index_to_tar[encoded_word] + ' '\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "y6L3zaLG7d2n"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "  print(\"Input :\",seq_to_src(encoder_input_train[seq_index]))\n",
        "  print(\"Label :\",seq_to_tar(decoder_input_train[seq_index]))\n",
        "  print(\"Output :\",decoded_sentence[1:-5])\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTpTaVUn7fea",
        "outputId": "422e870f-8b92-4b08-c34b-ba1a2298e111"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : get away . \n",
            "Label : partez . \n",
            "Output : degage . \n",
            "--------------------------------------------------\n",
            "Input : can you try ? \n",
            "Label : pouvez vous essayer ? \n",
            "Output : peux tu nous ? \n",
            "--------------------------------------------------\n",
            "Input : i struggled . \n",
            "Label : je me suis debattue . \n",
            "Output : je me suis debattue . \n",
            "--------------------------------------------------\n",
            "Input : go home now . \n",
            "Label : va a la maison maintenant . \n",
            "Output : va chez vous . \n",
            "--------------------------------------------------\n",
            "Input : cash is better . \n",
            "Label : de l argent liquide c est mieux . \n",
            "Output : le vois c est la voiture ! \n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "  print(\"Input :\",seq_to_src(encoder_input_test[seq_index]))\n",
        "  print(\"Label :\",seq_to_tar(decoder_input_test[seq_index]))\n",
        "  print(\"Output :\",decoded_sentence[1:-5])\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-MwOKuI7jLO",
        "outputId": "2471a711-28dc-4b14-be42-09372a68222a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : i couldn t find it . \n",
            "Label : je ne pus le trouver . \n",
            "Output : je ne l ai pas fait . \n",
            "--------------------------------------------------\n",
            "Input : i m thorough . \n",
            "Label : je suis consciencieuse . \n",
            "Output : je suis attentif . \n",
            "--------------------------------------------------\n",
            "Input : i woke you up . \n",
            "Label : je vous ai reveille . \n",
            "Output : je t ai reveille . \n",
            "--------------------------------------------------\n",
            "Input : you can come . \n",
            "Label : vous pouvez venir . \n",
            "Output : tu peux venir . \n",
            "--------------------------------------------------\n",
            "Input : they re twins . \n",
            "Label : ils sont jumeaux . \n",
            "Output : elles sont jumelles . \n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}